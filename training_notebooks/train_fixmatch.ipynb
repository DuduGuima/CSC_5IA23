{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import kagglehub\n",
    "from torchvision.transforms import v2\n",
    "import os #for loading the data\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet,BasicBlock,Bottleneck,wide_resnet50_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import create_weak_aug,create_strong_aug,create_valid_transform\n",
    "weak = create_weak_aug(size = (224,224))\n",
    "strong = create_strong_aug(size = (224,224))\n",
    "valid_transform = create_valid_transform(size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(path,'train')\n",
    "valid_path = os.path.join(path,'validation')\n",
    "test_path = os.path.join(path,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the datasets with the created functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n"
     ]
    }
   ],
   "source": [
    "from datasets import unlabelled_TensorDataset,labelled_TensorDataset\n",
    "\n",
    "\n",
    "labelled_set = labelled_TensorDataset(name = valid_path, transform=weak)\n",
    "unlabelled_set = unlabelled_TensorDataset(name = train_path,transform=weak,target_transform=strong)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labelled set is then splitted by number of images for which label, the default is always 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our training parameters, using FixMatch's original paper https://arxiv.org/abs/2001.07685 as some influence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "epochs=100\n",
    "#Training params and FixMatch hyperParams\n",
    "batch_size = 16 #used for labelled data\n",
    "ratio = 4 #this is the main limitation, due to the GPU's memory capacity.\n",
    "loss_weight = 1.0\n",
    "#Optim Parameters\n",
    "lr = 1e-3\n",
    "momentum = 0.5\n",
    "weight_decay = 0.03\n",
    "nesterov=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "unlabel_loader = DataLoader(unlabelled_set,batch_size=int(ratio*batch_size),shuffle=True, pin_memory=True, num_workers=num_workers,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in FixMatch's paper, the threshold is used to know if the pseudolabels for each image will be used. Here, to keep using PyTorch's implementation of the CrossEntropy, when the prediction over the weak augmented version of the input is inferior to the threshold paremeter, its label will be 3, and therefore ignored during the reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "criterion = CrossEntropyLoss(ignore_index=3,reduction='none')#target is assumed to be a list of indexes in [0,C)(C is the number of classes)\n",
    "criterion.ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training resnet0.5_100.pth.tar\n",
      "Fixmatch with threshold:  0.5\n",
      "\u001b[34m[Epoch: 1/100]\u001b[0m Training\n",
      "\u001b[34m[Epoch: 1/100]\u001b[0m Avg loss: 1.0452 | Accuracy: 76.2347\n",
      "\u001b[34m[Epoch: 1/100]\u001b[0m Validation\n",
      "\u001b[34m[Epoch: 1/100]\u001b[0m Avg loss: 0.4155 | Accuracy: 12.7225\n",
      "\n",
      "\u001b[32mBest model so far. Saving model as model.pth\u001b[0m\n",
      "\n",
      "\u001b[34m[Epoch: 3/100]\u001b[0m Training\n",
      "\u001b[34m[Epoch: 3/100]\u001b[0m Avg loss: 0.6052 | Accuracy: 78.1924\n",
      "\u001b[34m[Epoch: 3/100]\u001b[0m Validation\n",
      "\u001b[34m[Epoch: 3/100]\u001b[0m Avg loss: 0.2749 | Accuracy: 14.3429\n",
      "\n",
      "\u001b[32mBest model so far. Saving model as model.pth\u001b[0m\n",
      "\n",
      "\u001b[34m[Epoch: 5/100]\u001b[0m Training\n",
      "\u001b[34m[Epoch: 5/100]\u001b[0m Avg loss: 0.3887 | Accuracy: 79.1184\n",
      "\u001b[34m[Epoch: 5/100]\u001b[0m Validation\n",
      "\u001b[34m[Epoch: 5/100]\u001b[0m Avg loss: 0.2682 | Accuracy: 14.5969\n",
      "\n",
      "\u001b[32mBest model so far. Saving model as model.pth\u001b[0m\n",
      "\n",
      "\u001b[34m[Epoch: 36/100]\u001b[0m Training\n",
      "\u001b[34m[Epoch: 36/100]\u001b[0m Avg loss: 0.2104 | Accuracy: 79.3235\n",
      "\u001b[34m[Epoch: 36/100]\u001b[0m Validation\n",
      "\u001b[34m[Epoch: 36/100]\u001b[0m Avg loss: 0.2617 | Accuracy: 14.8403\n",
      "\n",
      "\u001b[32mBest model so far. Saving model as model.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8888/api/kernels/d134261e-6030-44b7-a235-ff45955c9afc/restart?1740390388499 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from utils import epoch_loop,validate\n",
    "from itertools import product\n",
    "from utils import labelset_split\n",
    "\n",
    "\n",
    "models = ['resnet']\n",
    "thresh_vals = [0.5]\n",
    "label_samples = [100,250,500]\n",
    "for model,value,n_labels in product(models,thresh_vals,label_samples):\n",
    "    threshold = value\n",
    "    save_path = model+str(value)+\"_\"+str(n_labels)+\".pth.tar\"\n",
    "    print(\"We are training \"+save_path)\n",
    "    labelled_filtered_set,val_set = labelset_split(labelled_set,n_per_label=n_labels)\n",
    "    label_loader = DataLoader(labelled_filtered_set,batch_size=batch_size,shuffle=True, pin_memory=True, num_workers=num_workers,persistent_workers=True)\n",
    "    val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=True, pin_memory=True, num_workers=num_workers,persistent_workers=True)\n",
    "\n",
    "    if model == 'resnet':\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 2)#Configurations for WideResNet50\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr,momentum=momentum, weight_decay=weight_decay,nesterov=nesterov)\n",
    "\n",
    "    epoch_loop(model,label_loader,unlabel_loader,val_loader,optimizer,criterion,device,epochs,threshold,loss_weight,verbose=False,save_path=save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
